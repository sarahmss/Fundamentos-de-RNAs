{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"./content\")\n",
    "\n",
    "lm_dir = \"tf-levenberg-marquardt\"\n",
    "if not os.path.exists(lm_dir):\n",
    "  !git clone https://github.com/fabiodimarco/$lm_dir\n",
    "\n",
    "os.chdir(lm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "def peaks(grid):\n",
    "    x = np.linspace(-2, 2, grid)\n",
    "    y = np.linspace(-2, 2, grid)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    z = 3*(1-x)**2 * np.exp(-(x**2) - (y+1)**2) - 10*(x/5 - x**3 - y**5) * np.exp(-x**2 - y**2) - 1/3 * np.exp(-(x+1)**2 - y**2)\n",
    "    return x, y, z\n",
    "\n",
    "def create_dataframe(grid):\n",
    "   x, y, z = peaks(grid)\n",
    "   data = {'X': x.flatten(), 'Y': y.flatten(), 'Z': z.flatten()}\n",
    "   df = pd.DataFrame(data)\n",
    "   return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_25 = create_dataframe(grid=5)\n",
    "df_1000 = create_dataframe(grid=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    df = df.sample(frac=1).reset_index(drop=True)  # Randomiza as linhas\n",
    "\n",
    "    _input = np.vstack([df['X'], df['Y']]).T\n",
    "    _output = np.array(df['Z'])\n",
    "    return (_input, _output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 22:14:45.609754: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-23 22:14:45.643561: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 22:14:45.643598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 22:14:45.644907: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 22:14:45.651766: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-23 22:14:45.652678: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 22:14:46.684887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import levenberg_marquardt as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "\n",
    "class TrainWithSmallDataset:\n",
    "    def __init__(self, batch_size=1000, store=25):\n",
    "        self.batch_size = batch_size\n",
    "        self.betters = []\n",
    "        self.store = store\n",
    "\n",
    "    def create_dataset(self, input, output):\n",
    "      input = tf.expand_dims(tf.cast(input, tf.float32), axis=-1)\n",
    "      output = tf.expand_dims(tf.cast(output, tf.float32), axis=-1)\n",
    "\n",
    "      train_dataset = tf.data.Dataset.from_tensor_slices((input, output))\n",
    "      train_dataset = train_dataset.shuffle(len(input))\n",
    "      train_dataset = train_dataset.batch(self.batch_size).cache()\n",
    "      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      return (train_dataset, input, output)\n",
    "\n",
    "\n",
    "    def split_dataset(self, input, output, sup_input, sup_output):\n",
    "\n",
    "      input_train, input_vt, output_train, output_vt = train_test_split(input, output, test_size=0.3, random_state=42)\n",
    "      input_val, input_test, output_val, output_test = train_test_split(input_vt, output_vt, test_size=0.5, random_state=42)\n",
    "\n",
    "      self.train_dataset, self.train_input, self.train_output = self.create_dataset(input_train, output_train)\n",
    "      self.val_dataset, self.val_input, self.val_output = self.create_dataset(input_val, output_val)\n",
    "      self.test_dataset, self.test_input, self.test_output = self.create_dataset(input_test, output_test)\n",
    "      self.vt_dataset, self.vt_input, self.vt_output = self.create_dataset(input_vt, output_vt)\n",
    "      self.sup_dataset, self.sup_input, self.sup_output = self.create_dataset(sup_input, sup_output)\n",
    "      self.dataset, self.input, self.output = self.create_dataset(input, output)\n",
    "\n",
    "\n",
    "    def create_model(self, input_size=2, sumary=False):\n",
    "      regularizer = regularizers.L2(0.2)\n",
    "      initializer = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n",
    "\n",
    "      self.model = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(30,\n",
    "                                activation='tanh',\n",
    "                                input_shape=(input_size,),\n",
    "                                kernel_regularizer=regularizer,\n",
    "                                kernel_initializer=initializer,\n",
    "                                ),\n",
    "          tf.keras.layers.Dense(16,\n",
    "                                activation='tanh',\n",
    "                                kernel_regularizer=regularizer,\n",
    "                                kernel_initializer=initializer,\n",
    "                                ),\n",
    "          tf.keras.layers.Dense(1,\n",
    "                                activation='linear',\n",
    "                                kernel_regularizer=regularizer,\n",
    "                                kernel_initializer=initializer,\n",
    ")])\n",
    "\n",
    "      if (sumary == True):\n",
    "        self.model.summary()\n",
    "\n",
    "      self.model.compile(\n",
    "          optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "          loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "      self.lm_model = lm.ModelWrapper(\n",
    "          tf.keras.models.clone_model(self.model))\n",
    "\n",
    "      self.lm_model.compile(\n",
    "          optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "          loss=lm.MeanSquaredError())\n",
    "\n",
    "    def train_using_lm(self, train_dataset, epochs=1000):\n",
    "      early_stopping_monitor = EarlyStopping(monitor='val_loss',\n",
    "                                              patience=6,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "      t2_start = time.perf_counter()\n",
    "      self.results = self.lm_model.fit(train_dataset,\n",
    "                                            epochs=epochs,\n",
    "                                            validation_data=self.val_dataset,\n",
    "                                            callbacks=[early_stopping_monitor],\n",
    "                                            verbose=0)\n",
    "      t2_stop = time.perf_counter()\n",
    "      print(\"Elapsed time: \", t2_stop - t2_start)\n",
    "      print (\"Stopped at epoch: \", early_stopping_monitor.stopped_epoch)\n",
    "\n",
    "    def get_metrics(self):\n",
    "          self.sup_prediction = self.lm_model.predict(self.sup_input)\n",
    "          self.test_prediction = self.lm_model.predict(self.test_input)\n",
    "\n",
    "          pred = self.lm_model.predict(self.input).flatten()\n",
    "          test_pred = self.test_prediction.flatten()\n",
    "          val_pred = self.lm_model.predict(self.val_input).flatten()\n",
    "          vt_pred = self.lm_model.predict(self.vt_input).flatten()\n",
    "          sup_pred = self.sup_prediction.flatten()\n",
    "\n",
    "          r2 = r2_score(self.output, pred)\n",
    "          r2_test = r2_score(self.test_output, test_pred)\n",
    "          r2_val = r2_score(self.val_output, val_pred)\n",
    "          r2_vt = r2_score(self.vt_output, vt_pred)\n",
    "          r2_sup = r2_score(self.sup_output, sup_pred)\n",
    "\n",
    "          mse = mean_squared_error(self.output, pred)\n",
    "          mse_test = mean_squared_error(self.test_output, test_pred)\n",
    "          mse_val = mean_squared_error(self.val_output, val_pred)\n",
    "          mse_vt = mean_squared_error(self.vt_output, vt_pred)\n",
    "          mse_sup = mean_squared_error(self.sup_output, sup_pred)\n",
    "\n",
    "          metrics = {\n",
    "                          'r2': r2,\n",
    "                          'r2_sup': r2_sup,\n",
    "                          'r2_test': r2_test,\n",
    "                          'r2_val': r2_val,\n",
    "                          'r2_vt': r2_vt,\n",
    "                          'mse': mse,\n",
    "                          'mse_sup': mse_sup,\n",
    "                          'mse_test': mse_test,\n",
    "                          'mse_val': mse_val,\n",
    "                          'mse_vt': mse_vt\n",
    "                          }\n",
    "\n",
    "          return metrics\n",
    "\n",
    "\n",
    "    def plot_results(self):\n",
    "      fig = plt.figure(figsize=(18, 6))\n",
    "      ax0 = fig.add_subplot(1, 3, 1, projection='3d')\n",
    "      ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n",
    "      ax1 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "      ax0.set_title('Superficie Fit')\n",
    "      ax0.scatter(self.sup_input[:, 0], self.sup_input[:, 1], self.sup_prediction, c='r', marker='s', label=\"lm\")\n",
    "      ax0.scatter(self.sup_input[:, 0], self.sup_input[:, 1], self.sup_output, c='b', marker='o', label=\"reference\")\n",
    "      ax0.legend()\n",
    "\n",
    "      ax2.set_title('Teste Fit')\n",
    "      ax2.scatter(self.test_input[:, 0], self.test_input[:, 1], self.test_prediction, c='r', marker='s', label=\"lm\")\n",
    "      ax2.scatter(self.test_input[:, 0], self.test_input[:, 1], self.test_output, c='b', marker='o', label=\"reference\")\n",
    "      ax2.legend()\n",
    "\n",
    "      ax1.plot(self.results.history['loss'], label='Erro Treino')\n",
    "      ax1.plot(self.results.history['val_loss'], label='Erro validação')\n",
    "      ax1.set_title('Histórico de Treinamento')\n",
    "      ax1.set_ylabel('Função de Custo')\n",
    "      ax1.set_xlabel('Épocas de Treinamento')\n",
    "      ax1.legend(['Erro Treino', 'Erro validação'])\n",
    "\n",
    "      return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import saving\n",
    "from keras import models\n",
    "\n",
    "class Tester:\n",
    "  def __init__(self, run_times=500):\n",
    "    self.run_times = run_times\n",
    "    self.better_metrics = []\n",
    "\n",
    "  def PrepareTraining(self):\n",
    "    trainer = TrainWithSmallDataset()\n",
    "    input_25, output_25 = split_df(df_25)\n",
    "    input_1000, output_1000 = split_df(df_1000)\n",
    "    trainer.split_dataset(input_25, output_25, input_1000, output_1000)\n",
    "    return (trainer)\n",
    "\n",
    "  def Train(self, trainer, epochs=500):\n",
    "    trainer.create_model()\n",
    "    trainer.train_using_lm(trainer.train_dataset, epochs=epochs)\n",
    "    return(trainer.get_metrics(), trainer.lm_model)\n",
    "\n",
    "  def SaveModelWeights(self, model, fileName):\n",
    "    path = f\"../models/{fileName}.keras\"\n",
    "    open(path,'w').close()\n",
    "    model.save_weights(path)\n",
    "  \n",
    "  def SaveResults(self, trainer, fileName):\n",
    "    path = f\"../results/{fileName}.png\" \n",
    "    open(path,'w').close()\n",
    "    figure = trainer.plot_results()\n",
    "    figure.savefig(path)\n",
    "    plt.close(figure)\n",
    "\n",
    "  def Loop(self, sort_by, boundarie):\n",
    "    betters = 0\n",
    "\n",
    "    for i in range(self.run_times):\n",
    "      print (f\"++++++++++++++++++++++++++ {i + 1} ++++++++++++++++++++++++++\")\n",
    "      trainer = self.PrepareTraining()\n",
    "      metrics, model = self.Train(trainer)\n",
    "      if (metrics[sort_by] <= boundarie): # should be >= to acsending metrics\n",
    "        fileName = f\"model_{betters}\"\n",
    "        self.SaveModelWeights(model, fileName)\n",
    "        self.SaveResults(trainer, fileName)\n",
    "        self.better_metrics.append(metrics)\n",
    "        betters += 1\n",
    "\n",
    "  def DisplayBetterResults(self):\n",
    "    self.better_metrics.sort(key=lambda x: x['mse_sup'])\n",
    "    df = pd.DataFrame(self.better_metrics)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinando com 25 dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++++++++++++++ 1 ++++++++++++++++++++++++++\n",
      "Elapsed time:  0.8404400639992673\n",
      "Stopped at epoch:  7\n",
      "32/32 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "++++++++++++++++++++++++++ 2 ++++++++++++++++++++++++++\n",
      "Elapsed time:  0.5168610599994281\n",
      "Stopped at epoch:  7\n",
      "32/32 [==============================] - 0s 2ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "tester = Tester(run_times=250)\n",
    "tester.Loop(sort_by='mse_sup', boundarie=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_sup</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>r2_vt</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_sup</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mse_vt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.423037</td>\n",
       "      <td>-0.321562</td>\n",
       "      <td>-2.914126</td>\n",
       "      <td>-1.598319</td>\n",
       "      <td>-2.389622</td>\n",
       "      <td>5.972180</td>\n",
       "      <td>8.837295</td>\n",
       "      <td>2.493245</td>\n",
       "      <td>1.001898</td>\n",
       "      <td>1.747572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.430467</td>\n",
       "      <td>-0.325096</td>\n",
       "      <td>-0.662219</td>\n",
       "      <td>-0.716040</td>\n",
       "      <td>-0.433174</td>\n",
       "      <td>6.003364</td>\n",
       "      <td>8.860923</td>\n",
       "      <td>7.207542</td>\n",
       "      <td>2.188694</td>\n",
       "      <td>4.698118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         r2    r2_sup   r2_test    r2_val     r2_vt       mse   mse_sup  \\\n",
       "0 -0.423037 -0.321562 -2.914126 -1.598319 -2.389622  5.972180  8.837295   \n",
       "1 -0.430467 -0.325096 -0.662219 -0.716040 -0.433174  6.003364  8.860923   \n",
       "\n",
       "   mse_test   mse_val    mse_vt  \n",
       "0  2.493245  1.001898  1.747572  \n",
       "1  7.207542  2.188694  4.698118  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tester.DisplayBetterResults()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
