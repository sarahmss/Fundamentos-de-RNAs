{"cells":[{"cell_type":"markdown","metadata":{"id":"unTfqvN2VPoB"},"source":["# Test curve fitting\n","\n","The function `y = sinc(10 * x)` is fitted using a Shallow Neural Network with 61 parameters.\n","Despite the triviality of the problem, first-order methods such as Adam fail to converge, while Levenbergâ€“Marquardt converges rapidly with very low loss values. The values of learning_rate were chosen experimentally on the basis of the results obtained by each algorithm."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Jzb-I0BbcSkZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'tf-levenberg-marquardt'...\n","remote: Enumerating objects: 53, done.\u001b[K\n","remote: Counting objects: 100% (53/53), done.\u001b[K\n","remote: Compressing objects: 100% (38/38), done.\u001b[K\n","remote: Total 53 (delta 31), reused 29 (delta 14), pack-reused 0\u001b[K\n","Receiving objects: 100% (53/53), 32.99 KiB | 11.00 MiB/s, done.\n","Resolving deltas: 100% (31/31), done.\n"]}],"source":["import os\n","\n","os.chdir(\"../content\")\n","\n","lm_dir = \"tf-levenberg-marquardt\"\n","if not os.path.exists(lm_dir):\n","  !git clone https://github.com/fabiodimarco/$lm_dir\n","\n","os.chdir(lm_dir)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.15.0.post1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n","Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n","Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.35.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.60.0)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.2)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"]}],"source":["!pip install tensorflow "]},{"cell_type":"markdown","metadata":{"id":"CMfWCCyHvEjV"},"source":["# Setup Levenberg-Marquardt\n","### Install dependencies from GitHub"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"iWColE1aoHWm"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy.stats import zscore\n","from sklearn.preprocessing import MaxAbsScaler\n","\n","def peaks(grid):\n","    x = np.linspace(-2, 2, grid)\n","    y = np.linspace(-2, 2, grid)\n","    x, y = np.meshgrid(x, y)\n","    z = 3*(1-x)**2 * np.exp(-(x**2) - (y+1)**2) - 10*(x/5 - x**3 - y**5) * np.exp(-x**2 - y**2) - 1/3 * np.exp(-(x+1)**2 - y**2)\n","    return x, y, z\n","\n","def create_dataframe(grid):\n","   x, y, z = peaks(grid)\n","   data = {'X': x.flatten(), 'Y': y.flatten(), 'Z': z.flatten()}\n","   df = pd.DataFrame(data)\n","   return df"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"plx_suuCoHWn"},"outputs":[],"source":["df_25 = create_dataframe(grid=5)\n","df_1000 = create_dataframe(grid=32)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"JsTH8ULIoHWo"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","      <th>Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-2.0</td>\n","      <td>-2.0</td>\n","      <td>0.046835</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.0</td>\n","      <td>-2.0</td>\n","      <td>-0.592128</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.0</td>\n","      <td>-2.0</td>\n","      <td>-4.759612</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-2.0</td>\n","      <td>-2.102351</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2.0</td>\n","      <td>-2.0</td>\n","      <td>-0.061640</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>-2.0</td>\n","      <td>-1.0</td>\n","      <td>-0.130053</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>-1.0</td>\n","      <td>-1.0</td>\n","      <td>1.855892</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>-1.0</td>\n","      <td>-0.723906</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>1.0</td>\n","      <td>-1.0</td>\n","      <td>-0.272917</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2.0</td>\n","      <td>-1.0</td>\n","      <td>0.499636</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>-2.0</td>\n","      <td>0.0</td>\n","      <td>-1.332690</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>-1.0</td>\n","      <td>0.0</td>\n","      <td>-1.652345</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.981012</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>2.936930</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>1.412161</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>-2.0</td>\n","      <td>1.0</td>\n","      <td>-0.480759</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>-1.0</td>\n","      <td>1.0</td>\n","      <td>0.228899</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>3.688630</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.433789</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>0.580455</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>-2.0</td>\n","      <td>2.0</td>\n","      <td>0.079668</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>-1.0</td>\n","      <td>2.0</td>\n","      <td>2.096679</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>5.859129</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.209935</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>0.132849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      X    Y         Z\n","0  -2.0 -2.0  0.046835\n","1  -1.0 -2.0 -0.592128\n","2   0.0 -2.0 -4.759612\n","3   1.0 -2.0 -2.102351\n","4   2.0 -2.0 -0.061640\n","5  -2.0 -1.0 -0.130053\n","6  -1.0 -1.0  1.855892\n","7   0.0 -1.0 -0.723906\n","8   1.0 -1.0 -0.272917\n","9   2.0 -1.0  0.499636\n","10 -2.0  0.0 -1.332690\n","11 -1.0  0.0 -1.652345\n","12  0.0  0.0  0.981012\n","13  1.0  0.0  2.936930\n","14  2.0  0.0  1.412161\n","15 -2.0  1.0 -0.480759\n","16 -1.0  1.0  0.228899\n","17  0.0  1.0  3.688630\n","18  1.0  1.0  2.433789\n","19  2.0  1.0  0.580455\n","20 -2.0  2.0  0.079668\n","21 -1.0  2.0  2.096679\n","22  0.0  2.0  5.859129\n","23  1.0  2.0  2.209935\n","24  2.0  2.0  0.132849"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df_25"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2afHyMZyoHWo"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X</th>\n","      <th>Y</th>\n","      <th>Z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-2.000000</td>\n","      <td>-2.0</td>\n","      <td>0.046835</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-1.870968</td>\n","      <td>-2.0</td>\n","      <td>0.060663</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-1.741935</td>\n","      <td>-2.0</td>\n","      <td>0.070183</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.612903</td>\n","      <td>-2.0</td>\n","      <td>0.067332</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.483871</td>\n","      <td>-2.0</td>\n","      <td>0.039844</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1019</th>\n","      <td>1.483871</td>\n","      <td>2.0</td>\n","      <td>0.708371</td>\n","    </tr>\n","    <tr>\n","      <th>1020</th>\n","      <td>1.612903</td>\n","      <td>2.0</td>\n","      <td>0.487302</td>\n","    </tr>\n","    <tr>\n","      <th>1021</th>\n","      <td>1.741935</td>\n","      <td>2.0</td>\n","      <td>0.325461</td>\n","    </tr>\n","    <tr>\n","      <th>1022</th>\n","      <td>1.870968</td>\n","      <td>2.0</td>\n","      <td>0.211038</td>\n","    </tr>\n","    <tr>\n","      <th>1023</th>\n","      <td>2.000000</td>\n","      <td>2.0</td>\n","      <td>0.132849</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1024 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["             X    Y         Z\n","0    -2.000000 -2.0  0.046835\n","1    -1.870968 -2.0  0.060663\n","2    -1.741935 -2.0  0.070183\n","3    -1.612903 -2.0  0.067332\n","4    -1.483871 -2.0  0.039844\n","...        ...  ...       ...\n","1019  1.483871  2.0  0.708371\n","1020  1.612903  2.0  0.487302\n","1021  1.741935  2.0  0.325461\n","1022  1.870968  2.0  0.211038\n","1023  2.000000  2.0  0.132849\n","\n","[1024 rows x 3 columns]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df_1000"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"TUtHn7NIImco"},"outputs":[],"source":["def split_df(df):\n","    df = df.sample(frac=1).reset_index(drop=True)  # Randomiza as linhas\n","\n","    _input = np.vstack([df['X'], df['Y']]).T\n","    _output = np.array(df['Z'])\n","    return (_input, _output)"]},{"cell_type":"code","execution_count":20,"metadata":{"cellView":"both","id":"x_9bcKcxvbut"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import levenberg_marquardt as lm\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import r2_score, mean_squared_error\n","from keras import regularizers\n","from keras import initializers\n","\n","class TrainWithSmallDataset:\n","    def __init__(self, batch_size=1000, model=None):\n","      self.batch_size = batch_size\n","      # self.model = model\n","\n","    def create_dataset(self, input, output):\n","      input = tf.expand_dims(tf.cast(input, tf.float32), axis=-1)\n","      output = tf.expand_dims(tf.cast(output, tf.float32), axis=-1)\n","\n","      train_dataset = tf.data.Dataset.from_tensor_slices((input, output))\n","      train_dataset = train_dataset.shuffle(len(input))\n","      train_dataset = train_dataset.batch(self.batch_size).cache()\n","      train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","      return (train_dataset, input, output)\n","\n","\n","    def split_dataset(self, input, output, sup_input, sup_output):\n","\n","      input_train, input_vt, output_train, output_vt = train_test_split(input, output, test_size=0.3, random_state=42)\n","      input_val, input_test, output_val, output_test = train_test_split(input_vt, output_vt, test_size=0.5, random_state=42)\n","\n","      self.train_dataset, self.train_input, self.train_output = self.create_dataset(input_train, output_train)\n","      self.val_dataset, self.val_input, self.val_output = self.create_dataset(input_val, output_val)\n","      self.test_dataset, self.test_input, self.test_output = self.create_dataset(input_test, output_test)\n","      self.vt_dataset, self.vt_input, self.vt_output = self.create_dataset(input_vt, output_vt)\n","      self.sup_dataset, self.sup_input, self.sup_output = self.create_dataset(sup_input, sup_output)\n","      self.dataset, self.input, self.output = self.create_dataset(input, output)\n","\n","\n","    def create_model(self, input_size=2, sumary=False):\n","      regularizer = regularizers.L2(0.2)\n","      initializer = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=42)\n","\n","      self.model = tf.keras.Sequential([\n","          tf.keras.layers.Dense(30,\n","                                activation='tanh',\n","                                input_shape=(input_size,),\n","                                kernel_regularizer=regularizer,\n","                                kernel_initializer=initializer,\n","                                ),\n","          tf.keras.layers.Dense(16,\n","                                activation='tanh',\n","                                kernel_regularizer=regularizer,\n","                                kernel_initializer=initializer,\n","                                ),\n","          tf.keras.layers.Dense(1,\n","                                activation='linear',\n","                                kernel_regularizer=regularizer,\n","                                kernel_initializer=initializer,\n",")])\n","\n","      if (sumary == True):\n","        self.model.summary()\n","\n","      self.model.compile(\n","          optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n","          loss=tf.keras.losses.MeanSquaredError())\n","\n","      self.lm_model = lm.ModelWrapper(\n","          tf.keras.models.clone_model(self.model))\n","\n","      self.lm_model.compile(\n","          optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n","          loss=lm.MeanSquaredError())\n","\n","    def train_using_lm(self, train_dataset, epochs=1000):\n","      early_stopping_monitor = EarlyStopping(monitor='val_loss',\n","                                              patience=6,\n","                                              restore_best_weights=True)\n","\n","      t2_start = time.perf_counter()\n","      self.results = self.lm_model.fit(train_dataset,\n","                                            epochs=epochs,\n","                                            validation_data=self.val_dataset,\n","                                            callbacks=[early_stopping_monitor],\n","                                            verbose=0)\n","      t2_stop = time.perf_counter()\n","      print(\"Elapsed time: \", t2_stop - t2_start)\n","      print (\"Stopped at epoch: \", early_stopping_monitor.stopped_epoch)\n","\n","    def get_metrics(self):\n","      pred = self.lm_model.predict(self.input).flatten()\n","      test_pred = self.lm_model.predict(self.test_input).flatten()\n","      val_pred = self.lm_model.predict(self.val_input).flatten()\n","      vt_pred = self.lm_model.predict(self.vt_input).flatten()\n","      sup_pred = self.lm_model.predict(self.sup_input).flatten()\n","\n","      r2 = r2_score(self.output, pred)\n","      r2_test = r2_score(self.test_output, test_pred)\n","      r2_val = r2_score(self.val_output, val_pred)\n","      r2_vt = r2_score(self.vt_output, vt_pred)\n","      r2_sup = r2_score(self.sup_output, sup_pred)\n","\n","      mse = mean_squared_error(self.output, pred)\n","      mse_test = mean_squared_error(self.test_output, test_pred)\n","      mse_val = mean_squared_error(self.val_output, val_pred)\n","      mse_vt = mean_squared_error(self.vt_output, vt_pred)\n","      mse_sup = mean_squared_error(self.sup_output, sup_pred)\n","\n","      metrics = {\n","                      'r2': r2,\n","                      'r2_sup': r2_sup,\n","                      'r2_test': r2_test,\n","                      'r2_val': r2_val,\n","                      'r2_vt': r2_vt,\n","                      'mse': mse,\n","                      'mse_sup': mse_sup,\n","                      'mse_test': mse_test,\n","                      'mse_val': mse_val,\n","                      'mse_vt': mse_vt\n","                      }\n","\n","      return metrics\n","\n","\n","    def plot_results(self):\n","      sup_prediction = self.lm_model.predict(self.sup_input)\n","      test_prediction = self.lm_model.predict(self.test_input)\n","\n","      fig = plt.figure(figsize=(18, 6))\n","      ax0 = fig.add_subplot(1, 3, 1, projection='3d')\n","      ax2 = fig.add_subplot(1, 3, 2, projection='3d')\n","      ax1 = fig.add_subplot(1, 3, 3)\n","\n","      ax0.set_title('Superficie Fit')\n","      ax0.scatter(self.sup_input[:, 0], self.sup_input[:, 1], sup_prediction, c='r', marker='s', label=\"lm\")\n","      ax0.scatter(self.sup_input[:, 0], self.sup_input[:, 1], self.sup_output, c='b', marker='o', label=\"reference\")\n","      ax0.legend()\n","\n","      ax2.set_title('Teste Fit')\n","      ax2.scatter(self.test_input[:, 0], self.test_input[:, 1], test_prediction, c='r', marker='s', label=\"lm\")\n","      ax2.scatter(self.test_input[:, 0], self.test_input[:, 1], self.test_output, c='b', marker='o', label=\"reference\")\n","      ax2.legend()\n","\n","      ax1.plot(self.results.history['loss'], label='Erro Treino')\n","      ax1.plot(self.results.history['val_loss'], label='Erro validaÃ§Ã£o')\n","      ax1.set_title('HistÃ³rico de Treinamento')\n","      ax1.set_ylabel('FunÃ§Ã£o de Custo')\n","      ax1.set_xlabel('Ã‰pocas de Treinamento')\n","      ax1.legend(['Erro Treino', 'Erro validaÃ§Ã£o'])\n","\n","      plt.show()"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"K_zMvfq3ebmL"},"outputs":[],"source":["from keras import saving\n","from keras import models\n","\n","class Tester:\n","  def __init__(self, run_times=500):\n","    self.run_times = run_times\n","    self.metrics = []\n","    self.better_results = {}\n","\n","  def PrepareTraining(self, model=None):\n","    trainer = TrainWithSmallDataset()\n","    input_25, output_25 = split_df(df_25)\n","    input_1000, output_1000 = split_df(df_1000)\n","    trainer.split_dataset(input_25, output_25, input_1000, output_1000)\n","    return (trainer)\n","\n","  def Train(self, trainer, epochs=500):\n","    trainer.create_model()\n","    trainer.train_using_lm(trainer.train_dataset, epochs=epochs)\n","    metrics = trainer.get_metrics()\n","    return(metrics, trainer.model)\n","\n","  def Loop(self, sort_by, boundarie):\n","\n","    betters = 0\n","    for i in range(self.run_times):\n","      trainer = self.PrepareTraining()\n","      metrics, model = self.Train(trainer)\n","      self.metrics.append(metrics)\n","\n","      if (metrics[sort_by] <= boundarie): # should be >= to acsending metrics\n","        fileName = f\"/model_{betters}.keras\"\n","        path = f\"../../Teste01/models/\" + fileName\n","        open(path,'w').close()\n","\n","        self.better_results[path] = metrics\n","        saving.save_model(model, path)\n","        betters += 1\n","\n","  def PlotBetterResults(self):\n","    files = self.better_results.keys()\n","    metrics = self.better_results.values()\n","\n","    for i in range(len(metrics)):\n","      model = models.load_model(files[i])\n","      trainer = self.PrepareTraining(model)\n","      trainer.plot_results()\n","      print(metrics[i])"]},{"cell_type":"markdown","metadata":{"id":"QMyU6WQoy1cZ"},"source":["# Treinando com 25 dados"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["tester = Tester(run_times=2)"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Elapsed time:  0.42995825499929197\n","Stopped at epoch:  6\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 16ms/step\n","32/32 [==============================] - 0s 3ms/step\n","Elapsed time:  0.45205448900014744\n","Stopped at epoch:  7\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 29ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.4855678599997191\n","Stopped at epoch:  6\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.6017037729998265\n","Stopped at epoch:  7\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.4827077049994841\n","Stopped at epoch:  7\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.556725827000264\n","Stopped at epoch:  7\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.7983497819986951\n","Stopped at epoch:  7\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 15ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.44486045300072874\n","Stopped at epoch:  6\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 2ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2024-01-22 21:31:40.543470: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"]},{"name":"stdout","output_type":"stream","text":["Elapsed time:  4.375508217999595\n","Stopped at epoch:  96\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 14ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 2ms/step\n","Elapsed time:  0.7819021349987452\n","Stopped at epoch:  6\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 15ms/step\n","1/1 [==============================] - 0s 14ms/step\n","32/32 [==============================] - 0s 3ms/step\n"]}],"source":["tester.Loop(sort_by='mse_sup', boundarie=3.5)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
