{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Entrada\n",
    "- x1: Local da Coleta em km\n",
    "- x2: Nivel da Mare em m\n",
    "- x3: Umidade do Ar (%)\n",
    "- x4: Índice Pluvimétrico (mm)¹\n",
    "- x5: Temperatura (°C)\n",
    "\n",
    "### Saida\n",
    "- y1: pH\n",
    "- y2: Condutividade Elétrica (mS.cmˉ¹)\n",
    "- y3: Oxigênio Dissolvido (mg.Lˉ¹)\n",
    "- y4: Sólidos Totais Dissolvidos (ppm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/python/3.10.13/lib/python3.10/site-packages (24.0)\n",
      "Requirement already satisfied: tensorflow in /usr/local/python/3.10.13/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.26.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/codespace/.local/lib/python3.10/site-packages (from tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (0.35.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/codespace/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/codespace/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/python/3.10.13/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: openpyxl in /usr/local/python/3.10.13/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/python/3.10.13/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow \n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"./content\")\n",
    "\n",
    "lm_dir = \"tf-levenberg-marquardt\"\n",
    "if not os.path.exists(lm_dir):\n",
    "  !git clone https://github.com/fabiodimarco/$lm_dir\n",
    "\n",
    "os.chdir(lm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_dataframe(output, label):\n",
    "    df = pd.read_excel(\"../../../data.xlsx\")\n",
    "    x1, x2, x3, x4, x5  = df['x1'], df['x2'], df['x3'], df['x4'], df['x5']\n",
    "\n",
    "    input = np.vstack([x1, x2, x3, x4, x5 ]).T\n",
    "    output = np.array(df[output])\n",
    "    return output, input\n",
    "\n",
    "output, input = create_dataframe(output=\"y1\", label=\"ph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "import levenberg_marquardt as lm\n",
    "\n",
    "# layers, neurons\n",
    "class ShuffleArchitecture:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, act_h, act_o, param_reg):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.act_h = act_h\n",
    "        self.act_o = act_o\n",
    "        self.regularizer = regularizers.L2(param_reg)\n",
    "        self.initializer = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=np.random.randint(1, 10000))\n",
    "\n",
    "    def set_architecture(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Dense(self.hidden_sizes[0],\n",
    "                        input_shape=(self.input_size,),\n",
    "                        activation=self.act_h,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,                        \n",
    "                        ))  # input layer\n",
    "        \n",
    "        for size in self.hidden_sizes[1:]:  # hidden layers\n",
    "            self.model.add(tf.keras.layers.Dense(size,\n",
    "                            activation=self.act_h,\n",
    "                            kernel_regularizer=self.regularizer,\n",
    "                            kernel_initializer=self.initializer,  \n",
    "                        ))\n",
    "\n",
    "        self.model.add(tf.keras.layers.Dense(self.output_size,\n",
    "                        activation=self.act_o,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,  \n",
    "                        ))  # output layer\n",
    "\n",
    "    def create_model(self, _learning_rate):\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=_learning_rate),\n",
    "            loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "        self.lm_model = lm.ModelWrapper(\n",
    "            tf.keras.models.clone_model(self.model))\n",
    "\n",
    "        self.lm_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=_learning_rate),\n",
    "            loss=lm.MeanSquaredError())\n",
    "        return(self.lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "class TrainWithSmallDataset:\n",
    "    def __init__(self, batch_size=1000):\n",
    "        self.batch_size = batch_size\n",
    "        self.betters = []\n",
    "    \n",
    "    def create_dataset(self, input, output):\n",
    "      input = tf.expand_dims(tf.cast(input, tf.float32), axis=-1)\n",
    "      output = tf.expand_dims(tf.cast(output, tf.float32), axis=-1)\n",
    "\n",
    "      dataset = tf.data.Dataset.from_tensor_slices((input, output))\n",
    "      dataset = dataset.shuffle(len(input))\n",
    "      dataset = dataset.batch(self.batch_size).cache()\n",
    "      dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "      return (dataset, input, output)\n",
    "\n",
    "    def split_dataset(self, input, output):\n",
    "      input_train, input_vt, output_train, output_vt = train_test_split(input, output, test_size=0.3, shuffle = True)\n",
    "      input_val, input_test, output_val, output_test = train_test_split(input_vt, output_vt, test_size=0.5, shuffle = True)\n",
    "\n",
    "      self.train_dataset, self.train_input, self.train_output = self.create_dataset(input_train, output_train)\n",
    "      self.val_dataset, self.val_input, self.val_output = self.create_dataset(input_val, output_val)\n",
    "      self.test_dataset, self.test_input, self.test_output = self.create_dataset(input_test, output_test)\n",
    "      self.vt_dataset, self.vt_input, self.vt_output = self.create_dataset(input_vt, output_vt)\n",
    "      self.dataset, self.input, self.output = self.create_dataset(input, output)\n",
    "\n",
    "      self._train = (input_train, output_train)\n",
    "      self._vt = (input_vt, output_vt)\n",
    "      self._val = (input_val, output_val)\n",
    "      self._test = (input_test, output_test)\n",
    " \n",
    " \n",
    "    \n",
    "    def train_using_lm(self, train_dataset, epochs=1000):\n",
    "      early_stopping_monitor = EarlyStopping(monitor='val_loss',\n",
    "                                              patience=6,\n",
    "                                              restore_best_weights=True)\n",
    "\n",
    "      t2_start = time.perf_counter()\n",
    "      self.results = self.lm_model.fit(train_dataset,\n",
    "                                            epochs=epochs,\n",
    "                                            validation_data=self.val_dataset,\n",
    "                                            callbacks=[early_stopping_monitor],\n",
    "                                            verbose=0)\n",
    "      t2_stop = time.perf_counter()\n",
    "      print(\"Elapsed time: \", t2_stop - t2_start)\n",
    "      print (\"Stopped at epoch: \", early_stopping_monitor.stopped_epoch)\n",
    "\n",
    "    def get_metrics(self):\n",
    "          self.test_prediction = self.lm_model.predict(self.test_input)\n",
    "\n",
    "          pred = self.lm_model.predict(self.input).flatten()\n",
    "          test_pred = self.test_prediction.flatten()\n",
    "          val_pred = self.lm_model.predict(self.val_input).flatten()\n",
    "          vt_pred = self.lm_model.predict(self.vt_input).flatten()\n",
    "\n",
    "          r2 = r2_score(self.output, pred)\n",
    "          r2_test = r2_score(self.test_output, test_pred)\n",
    "          r2_val = r2_score(self.val_output, val_pred)\n",
    "          r2_vt = r2_score(self.vt_output, vt_pred)\n",
    "\n",
    "          mse = mean_squared_error(self.output, pred)\n",
    "          mse_test = mean_squared_error(self.test_output, test_pred)\n",
    "          mse_val = mean_squared_error(self.val_output, val_pred)\n",
    "          mse_vt = mean_squared_error(self.vt_output, vt_pred)\n",
    "\n",
    "          metrics = {\n",
    "                          'r2': r2,\n",
    "                          'r2_test': r2_test,\n",
    "                          'r2_val': r2_val,\n",
    "                          'r2_vt': r2_vt,\n",
    "                          'mse': mse,\n",
    "                          'mse_test': mse_test,\n",
    "                          'mse_val': mse_val,\n",
    "                          'mse_vt': mse_vt\n",
    "                          }\n",
    "\n",
    "          return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pickle\n",
    "\n",
    "class Tester:\n",
    "  def __init__(self, input, output, run_times=500, dataset_run_times=10):\n",
    "    self.run_times = run_times\n",
    "    self.better_metrics = {}\n",
    "    self.dataset_run_times = dataset_run_times\n",
    "    self.input, self.output = input, output\n",
    "  \n",
    "  def setArchitecure(self, trainer, _hidden_sizes, _pg, _lr):\n",
    "    shuffler = ShuffleArchitecture(input_size=5,\n",
    "                                    hidden_sizes=_hidden_sizes,\n",
    "                                    output_size=1,\n",
    "                                    act_h='tanh',\n",
    "                                    act_o='linear',\n",
    "                                    param_reg=_pg)\n",
    "    shuffler.set_architecture()    \n",
    "    trainer.lm_model = shuffler.create_model(_lr)\n",
    "\n",
    "  def Train(self, trainer, epochs=1000):\n",
    "    trainer.train_using_lm(trainer.train_dataset, epochs=epochs)\n",
    "    return(trainer.get_metrics(), trainer.lm_model)\n",
    "\n",
    "  def SaveModelWeights(self, model, fileName):\n",
    "    path = f\"../models/{fileName}.keras\"\n",
    "    open(path,'w').close()\n",
    "    model.save_weights(path) \n",
    "\n",
    "  def SaveDataset(self, trainer, fileName):\n",
    "    path = f\"../dataset/{fileName}.pkl\" \n",
    "    with open(path, 'wb') as f:\n",
    "      pickle.dump((trainer._train, trainer._vt, trainer._val, trainer._test), f)\n",
    "\n",
    "\n",
    "  def LoopWeights(self, sort_by, boundarie, trainer, idx):\n",
    "    better_model = 0\n",
    "    save = False\n",
    "\n",
    "    for i in range(self.run_times):\n",
    "      print (f\"+++++++++++ [{idx}] | {i + 1} ++++++++++++++++++\")\n",
    "      metrics, model = self.Train(trainer)\n",
    "      if (metrics[sort_by] >= boundarie): # should be <= to descending metrics\n",
    "        fileName = f\"model_{idx}_{better_model}\"\n",
    "        self.SaveModelWeights(model, fileName)\n",
    "        self.better_metrics[fileName] = metrics\n",
    "        better_model += 1\n",
    "        save = True\n",
    "    \n",
    "    return(save)\n",
    "\n",
    "# Init\n",
    "  def Loop(self, sort_by, boundarie, hidden_sizes, regularizers, learning_rate):\n",
    "    trainer = TrainWithSmallDataset()\n",
    "\n",
    "    for count, (hidden_size, reg, lr) in enumerate(product(hidden_sizes, regularizers, learning_rate), start=1):\n",
    "      header =  f\"Hidden Size={hidden_size}, regularizer={reg}, learning_rate={lr}\"\n",
    "      print(f\"Testando combinacao{count}: {header}\")\n",
    "      self.setArchitecure(trainer, hidden_size, reg, lr)\n",
    "      for j in range(self.dataset_run_times):\n",
    "        trainer.split_dataset(self.input, self.output)\n",
    "        if (self.LoopWeights(sort_by, boundarie, trainer, f\"{count}_{j}\") == True):\n",
    "          self.SaveDataset(trainer, f\"dataset_{count}_{j}\")\n",
    "          self.DisplayBetterResults(sort_by, header, f\"{count}_{j}\")\n",
    "        self.better_metrics = {}\n",
    "\n",
    "  def DisplayBetterResults(self, sort_by, header, dataset=0):\n",
    "    df = pd.DataFrame.from_dict(self.better_metrics, orient='index')\n",
    "    df = df.sort_values([sort_by])\n",
    "    display(df)\n",
    "    path = f'../results/metrics_{dataset}'\n",
    "    df.to_excel(f\"{path}.xlsx\", index=True)\n",
    "    print(f\"DataFrame salvo em {path}\")\n",
    "    with open(f\"{path}.txt\", 'w') as arquivo:\n",
    "      arquivo.write(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = Tester(input, output, run_times=25, dataset_run_times=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando combinacao1: Hidden Size=[15, 2], regularizer=0.02, learning_rate=0.01\n",
      "+++++++++++ [1_0] | 1 ++++++++++++++++++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  0.6138265160006995\n",
      "Stopped at epoch:  10\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++ [1_0] | 2 ++++++++++++++++++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 01:39:00.100679: W tensorflow/core/data/root_dataset.cc:342] Optimization loop failed: CANCELLED: Operation was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  11.624186805000136\n",
      "Stopped at epoch:  278\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>r2_vt</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mse_vt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1_0_0</th>\n",
       "      <td>-0.057449</td>\n",
       "      <td>-0.588261</td>\n",
       "      <td>-0.046839</td>\n",
       "      <td>-0.33456</td>\n",
       "      <td>0.197825</td>\n",
       "      <td>0.375092</td>\n",
       "      <td>0.142277</td>\n",
       "      <td>0.265532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r2   r2_test    r2_val    r2_vt       mse  mse_test  \\\n",
       "model_1_0_0 -0.057449 -0.588261 -0.046839 -0.33456  0.197825  0.375092   \n",
       "\n",
       "              mse_val    mse_vt  \n",
       "model_1_0_0  0.142277  0.265532  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame salvo em ../results/metrics_1_0\n",
      "+++++++++++ [1_1] | 1 ++++++++++++++++++\n",
      "Elapsed time:  0.277859587000421\n",
      "Stopped at epoch:  6\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "+++++++++++ [1_1] | 2 ++++++++++++++++++\n",
      "Elapsed time:  0.9783045559997845\n",
      "Stopped at epoch:  22\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2</th>\n",
       "      <th>r2_test</th>\n",
       "      <th>r2_val</th>\n",
       "      <th>r2_vt</th>\n",
       "      <th>mse</th>\n",
       "      <th>mse_test</th>\n",
       "      <th>mse_val</th>\n",
       "      <th>mse_vt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1_1_0</th>\n",
       "      <td>-0.033274</td>\n",
       "      <td>0.174423</td>\n",
       "      <td>-0.182896</td>\n",
       "      <td>0.034071</td>\n",
       "      <td>0.193302</td>\n",
       "      <td>0.206871</td>\n",
       "      <td>0.228410</td>\n",
       "      <td>0.217007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1_1_1</th>\n",
       "      <td>0.049181</td>\n",
       "      <td>0.128184</td>\n",
       "      <td>-0.085307</td>\n",
       "      <td>0.046239</td>\n",
       "      <td>0.177877</td>\n",
       "      <td>0.218458</td>\n",
       "      <td>0.209566</td>\n",
       "      <td>0.214273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   r2   r2_test    r2_val     r2_vt       mse  mse_test  \\\n",
       "model_1_1_0 -0.033274  0.174423 -0.182896  0.034071  0.193302  0.206871   \n",
       "model_1_1_1  0.049181  0.128184 -0.085307  0.046239  0.177877  0.218458   \n",
       "\n",
       "              mse_val    mse_vt  \n",
       "model_1_1_0  0.228410  0.217007  \n",
       "model_1_1_1  0.209566  0.214273  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame salvo em ../results/metrics_1_1\n"
     ]
    }
   ],
   "source": [
    "tester.Loop(sort_by='r2',\n",
    "            boundarie=-1.0,\n",
    "            hidden_sizes = [[15, 7], [30, 15], [30, 15, 7]],\n",
    "            regularizers=[0.02, 0.1],\n",
    "            learning_rate=[0.02, 0.1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
